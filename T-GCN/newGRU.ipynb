{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42176741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>> standard libs\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3897f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>> basic 3rd libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7aa541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch libs\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a628b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>> my libs\n",
    "sys.path.append('../../ai.rdee')\n",
    "import air"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c9f2c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c08bf99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6e6c7",
   "metadata": {},
   "source": [
    "# 1. 首先, 实现air库中的Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e979ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SZD4GRU(air.utils.airDataset, torch.utils.data.Dataset):\n",
    "    def __init__(self, scaler=None):\n",
    "        air.utils.airDataset.__init__(self)\n",
    "        \n",
    "        for f in self.processed_file_names:\n",
    "            if not os.path.exists(f):\n",
    "                self.process()\n",
    "        self.data = torch.load(self.processed_file_names[0])  # (nSamples, nFeatures, nNodes)\n",
    "        self._index = list(range(self.data.shape[0]))\n",
    "        \n",
    "        self.scalerX = scaler() if scaler is not None else air.utils.NoScaler()\n",
    "        self.scalerY = self.scalerX\n",
    "\n",
    "        self.nNodes = self.data.shape[2]\n",
    "        self.parent = None\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data/sz_adj.csv', 'data/sz_speed.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_sz_GRU.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        print(\"Please download the data manually!\")\n",
    "        sys.exit(0)\n",
    "        \n",
    "    def process(self):\n",
    "        for f in self.raw_file_names:\n",
    "            if not os.path.exists(f):\n",
    "                slef.download()\n",
    "                break\n",
    "        print(\"Processing ... ...\")\n",
    "        # Read data into huge `Data` list.\n",
    "        fn_adj, fn_spd = self.raw_file_names\n",
    "        df_spd = pd.read_csv(fn_spd)\n",
    "        S = df_spd.values  # nTimes x nNodes\n",
    "        \n",
    "        data = np.zeros((S.shape[0]-14, 15, S.shape[1]))  # (nSamples, nSeq, nNodes)\n",
    "        for i in range(data.shape[0]):\n",
    "            data[i,:,:] = S[i:i+15, :]\n",
    "        \n",
    "        torch.save(torch.Tensor(data), self.processed_file_names[0])\n",
    "        print(\"Process done.\")\n",
    "        \n",
    "    def clean(self):\n",
    "        os.remove('data_sz_GRU.pt')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.data[idx, :, :]\n",
    "    \n",
    "    @property\n",
    "    def feature_dim(self):\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def target(self):\n",
    "        return \"speed\"\n",
    "    \n",
    "    @property\n",
    "    def index(self):\n",
    "        return self._index\n",
    "    \n",
    "    @index.setter\n",
    "    def index(self, indices):\n",
    "        self._index = indices\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def Y(self):\n",
    "        pass\n",
    "    \n",
    "    def loader(self, batch_size):\n",
    "        def collate_fn(batch):\n",
    "            batchTS = torch.stack(batch)  # (batch_size, nSeq, nNodes)\n",
    "            return batchTS[:, :12, :].permute(0,2,1).contiguous(), batchTS[:, 12:, :].permute(0,2,1).contiguous()\n",
    "        #     return batchTS[:, :12, :], batchTS[:, 12:, :].permute(0, 2, 1).contiguous()\n",
    "        #     return batchTS[:, :12, :].permute(0,2,1).contiguous(), batchTS[:, 12:, :].permute(0,2,1).contiguous()# .view(batchTS.shape[0], -1)\n",
    "        return torch.utils.data.DataLoader(self, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    def scale(self, inverse=False):\n",
    "        assert not self.is_subset, 'This dataset only suport global scale!'\n",
    "        self.data = self.scalerX(self.data, along=self.feature_dim, inverse=inverse)\n",
    "    \n",
    "    def stat(self):\n",
    "        print(f\"mean = {self.data.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a7b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SZD4GRU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc59080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dts_train, dts_valid, dts_test = dataset.random_split([0.7, 0.2, 0.1])\n",
    "dts_train, dts_valid = dataset.random_split([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a091b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 12.19403076171875\n"
     ]
    }
   ],
   "source": [
    "dts_valid.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8af816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlr_train = dts_train.loader(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f955b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(dlr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df446456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 156, 12]), torch.Size([64, 156, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbb866",
   "metadata": {},
   "source": [
    "# 2. 然后构建net\n",
    "\n",
    "+ 这里又去看了TGCN里的code半天, 发现他的本质其实是input_dim为1的, hidden到100, output再到3, 如此而已\n",
    "+ 证据就是做hidden_state的时候, i和h要加的嘛, 他就1+的, 另外, hidden_state的值, 就是nNodes * (1+hidden_dim)\n",
    "+ 所以nNodes还是充当了batch的角色, 额, 但是他不考虑相互关系就可以做到这么好的效果?试试吧先..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f164adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nNodes = dataset.nNodes\n",
    "nNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b93bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, nNodes, input_dim, GRU_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.GRULayer = nn.GRU(input_dim, GRU_dim, batch_first=True)\n",
    "        self.Regressor = nn.Linear(GRU_dim, output_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_nodes, seq_len = inputs.shape\n",
    "#         h0 = torch.zeros(batch_size, num_nodes * self.GRU_dim).type_as(\n",
    "#             inputs\n",
    "#         )\n",
    "#         print(inputs.shape)\n",
    "        out, h_gru = self.GRULayer(inputs.view(batch_size * num_nodes, seq_len, 1))  # h_gru : (1, batchsize, hidden_dim)\n",
    "#         print(h_gru.shape)\n",
    "        x = self.Regressor(h_gru.squeeze(0))\n",
    "        return x.view(batch_size, num_nodes, -1)  # x(batch_size * num_nodes, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bb368",
   "metadata": {},
   "source": [
    "## 测试一下net的forward, 检查shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021358f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GRU(nNodes, 1, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92630761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 156, 3]), torch.Size([64, 156, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya = net(a)\n",
    "assert(ya.shape == b.shape), 'Shape differs'\n",
    "ya.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d399bba",
   "metadata": {},
   "source": [
    "## 没有问题, 下面开始搭框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fd0bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a62203d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (GRULayer): GRU(1, 100, batch_first=True)\n",
       "  (Regressor): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d8babc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee7526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losser = torch.nn.MSELoss()\n",
    "# optim = torch.optim.Adam(net.parameters())\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1.5e-3)\n",
    "\n",
    "esp = air.utils.EarlyStopping(30)\n",
    "\n",
    "trainer = air.airTrainer(net, criterion=losser, optim=optim, esp=esp, max_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "146de4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "apf = air.airPerf(task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df4cada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = air.airRunner(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0c06d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> repeat time 0 @ 2023/10/29 16:45:43\n",
      "Hint: feature_dim is None in evaluation\n",
      "[ 0/30] train_loss: 291.5840, valid_loss: 406.6052, min_loss : 406.6052, @2023/10/29 16:45:45\n",
      "[10/30] train_loss: 64.4351, valid_loss: 124.2020, min_loss : 124.2020, @2023/10/29 16:45:54\n",
      "[20/30] train_loss: 45.2829, valid_loss: 88.2626, min_loss : 88.2626, @2023/10/29 16:46:03\n"
     ]
    }
   ],
   "source": [
    "runner.split_run(dataset, apf, learn_ratio=1, train_core_params={\n",
    "    'batch_size': 64,\n",
    "    'verbose_nEpoch': 10\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc521235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 12.19403076171875\n"
     ]
    }
   ],
   "source": [
    "dts_valid.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f89250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
