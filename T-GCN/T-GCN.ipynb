{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea58020",
   "metadata": {},
   "source": [
    "## T-GCN\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "+ 先理一下, 看看论文和代码\n",
    "+ 唔, 他这个就等于做完GraphConv之后扔到GRU里去算一个hidden state, 或者说output\n",
    "+ 那这个hidden的shape是? ok自己指定的\n",
    "+ 所以我要使用PyG做的话, 应该就是套着来, 写个loop, 里面是conv得到的结果扔到GRU\n",
    "+ 但是有个问题, GRU默认自己处理多个seq的, 我这种不是等于单步的去处理吗?\n",
    "+ 不对, 每个seq的conv本身又不依赖hidden state, 所以我就是每个seq都做conv之后, 再把seq作为seq扔到gru里去应该就可以\n",
    "+ 就是得处理shape的问题, 这个麻烦..\n",
    "***\n",
    "+ 仔细看了他的代码, 额, 他是在原本GCN里的`AXW+b`这个式子里, 强行给X加了个h, 变成`A[X+h]W +b`, 然后去先更新一次Conv, 再去做GRU, 手动loop实现seq里h的迭代\n",
    "+ 额, 和我想的还不太一样那.....\n",
    "***\n",
    "+ 我懂了, 他其实是把GRU里hidden state的更新也考虑了连接节点的影响, 就是不是`xW+b`, 而还是`AxW+b`, 额, 话说有必要吗, 如果我这样呢? `((AxW+b)+h)*W2+b2`, 就是我hidden_state不做A左乘, 而是直接拿去做计算? 感觉可以试试, 就当增进理解了..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b5e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa55f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78163dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b248bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric as PyG\n",
    "# from torch.nn import Linear\n",
    "# import torch.nn as nn\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "# from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../ai.rdee')\n",
    "\n",
    "import ai_rdee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6ed210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffa23191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "\n",
    "class TGCN_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data/sz_adj.csv', 'data/sz_speed.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_sz.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        fn_adj, fn_spd = self.raw_file_names\n",
    "        df_spd = pd.read_csv(fn_spd)\n",
    "        S = df_spd.values.T\n",
    "        df_adj = pd.read_csv(fn_adj, index_col=None, header = None)\n",
    "\n",
    "        A = df_adj.values\n",
    "        A.shape\n",
    "\n",
    "        eis = torch.tensor(np.argwhere(A == 1).T)\n",
    "        S = torch.Tensor(S)\n",
    "        data_list = []\n",
    "        for i in range(S.shape[1]-14):\n",
    "            data = Data(x=S[:,i:i+12], y=S[:,i+12:i+15], edge_index=eis)\n",
    "            data_list.append(data)\n",
    "        \n",
    "        \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "506b20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsG = TGCN_dataset('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2348aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_test = 0.2\n",
    "size_test = int(ratio_test * len(dsG))\n",
    "size_learn = len(dsG) - size_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47284b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsG_train, dsG_test = torch.utils.data.random_split(dsG, [size_learn, size_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d5d13f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlr_train = PyG.loader.DataLoader(dsG_train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08ef31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563a836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf82ad3e",
   "metadata": {},
   "source": [
    "## Below blcok is used to check the data operation correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e1aba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlr = PyG.loader.DataLoader(dsG, batch_size=64, shuffle=False)\n",
    "\n",
    "k = next(iter(dlr))\n",
    "x = k.x\n",
    "\n",
    "# x.shape\n",
    "# x.view(64, -1, 12).shape\n",
    "\n",
    "x2 = x.view(64, -1, 12).permute(2,0,1)\n",
    "# x2.shape\n",
    "# x2[:,0,:]\n",
    "\n",
    "df = pd.read_csv('data/sz_speed.csv')\n",
    "# df.iloc[:12, :].values\n",
    "(x2[:,0,:] - torch.Tensor(df.iloc[:12, :].values)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f80d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfa603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cd8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf34006",
   "metadata": {},
   "source": [
    "+ **GCN operator:**\n",
    "\n",
    "$\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},$\n",
    "\n",
    "+ **GRU operator:**\n",
    "\n",
    "$r= \\sigma ( W_ {ir} x + b_ {ir} + W_ {hr} h+ b_ {hr} )$\n",
    "\n",
    "$z= \\sigma  (  W_ {iz}  x+  b_ {iz}  +  W_ {hz}  h+  b_ {hz}  )$\n",
    "\n",
    "$n=  \\tanh  (  W_ {in}  x+  b_ {in}  +r*(  W_ {hn}  h+  b_ {hn}  ))$\n",
    "\n",
    "$h'=(1-z)*n+z*h$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbc777",
   "metadata": {},
   "source": [
    "+ 一种思路(T-GCN, GCN1GRU), 把GCN嵌入到GRU里去, 即在$W_ir, W_hr$等weight前都乘上一个$\\hat{A}_{DD}$\n",
    "+ 另一种思路(GCN2GRU), 把GCN传给GRU, 即GRU公式里的x是GCN得到的$X^{'}$\n",
    "+ 都试试吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e0100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62c0f3f",
   "metadata": {},
   "source": [
    "## GCN2GRU\n",
    "\n",
    "+ 我靠, 不对啊, 有个问题, 我GCN完了之后, sequence就没了啊, 因为我变成了额, 一个hidden dim的feature, 他不再是那什么了?\n",
    "+ 但是换个思路, 如果把12个也当成图, 我只要hidden dim是12的倍数, 然后拆出来得到seq就好?比如36, 那我理解为每个seq变成3个attr, 再和nnodes相乘, 变成seq, nnodes*nfeatures这样? 似乎也说得过去...试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b564ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN2GRU(torch.nn.Module):  # \n",
    "    def __init__(self, input_dim, hidden_dim_GCN, hidden_dim_GRU, output_dim):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(925)\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim) # 只需定义好输入特征和输出特征即可\n",
    "        self.gru = torch.nn.GRU(hidden_dim_GCN/input_dim*156, 156*64)\n",
    "        self.regressor = Linear(156*64, 156*3)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x : (batch_size, nnodes, nFeatrues)\n",
    "        \n",
    "        h = self.conv1(x, edge_index) # h: (batch_size, nNodes, n_hiddenG)\n",
    "        h = h.tanh()\n",
    "        \n",
    "        # 分类层\n",
    "        out = self.regressor(h)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32226f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4dbc6bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ... ...\n",
      "Process done.\n"
     ]
    }
   ],
   "source": [
    "ds = TGCN_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a39b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b3101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
